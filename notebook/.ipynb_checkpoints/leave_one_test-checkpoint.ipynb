{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc554cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:44:13.902189Z",
     "start_time": "2024-12-16T20:44:13.891666Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def extract_features(keypoints):\n",
    "    \"\"\"\n",
    "    Extract features from 3D keypoints, adding a vertical nose offset feature\n",
    "    to help distinguish backward vs. normal posture.\n",
    "\n",
    "    Args:\n",
    "        keypoints (np.array): shape (17, 3), each row is (x, y, z)\n",
    "\n",
    "    Returns:\n",
    "        np.array: Extracted features (including vertical_nose_offset)\n",
    "    \"\"\"\n",
    "    # Indices (assuming COCO-style or similar)\n",
    "    nose = keypoints[0]            # (x, y, z)\n",
    "    left_shoulder = keypoints[11]  # (x, y, z)\n",
    "    right_shoulder = keypoints[12] # (x, y, z)\n",
    "    if np.isnan(nose).any():\n",
    "        return np.full((8,), np.nan)\n",
    "\n",
    "    # 1. Shoulder line & length\n",
    "    shoulder_vector = right_shoulder - left_shoulder\n",
    "    shoulder_length = np.linalg.norm(shoulder_vector)\n",
    "\n",
    "    # Horizontal angle (projection onto the XY plane)\n",
    "    horizontal_angle = np.arctan2(shoulder_vector[1], shoulder_vector[0])\n",
    "\n",
    "    # Vertical angle (projection onto the XZ plane)\n",
    "    vertical_angle = np.arctan2(\n",
    "        shoulder_vector[2],\n",
    "        np.sqrt(shoulder_vector[0]**2 + shoulder_vector[1]**2)\n",
    "    )\n",
    "\n",
    "    # Depth angle (projection onto the YZ plane)\n",
    "    depth_angle = np.arctan2(\n",
    "        shoulder_vector[2],\n",
    "        np.sqrt(shoulder_vector[0]**2 + shoulder_vector[1]**2 + shoulder_vector[2]**2)\n",
    "    )\n",
    "\n",
    "    # 3. Nose deviation from shoulder line (existing feature)\n",
    "    if shoulder_length != 0:\n",
    "        shoulder_unit_vector = shoulder_vector / shoulder_length\n",
    "    else:\n",
    "        shoulder_unit_vector = np.array([0, 0, 0])  # degenerate case\n",
    "\n",
    "    nose_projection = np.dot(nose - left_shoulder, shoulder_unit_vector)\n",
    "    nose_deviation = np.linalg.norm((nose - left_shoulder) - nose_projection * shoulder_unit_vector)\n",
    "\n",
    "    # 4. Z offset (if you already have it)\n",
    "    mid_shoulder = (left_shoulder + right_shoulder) / 2.0\n",
    "    z_offset = nose[2] - mid_shoulder[2]  # forward/back offset\n",
    "\n",
    "    # 5. **NEW** vertical offset (assuming y is vertical)\n",
    "\n",
    "    # Existing distance calculation\n",
    "    nose_distance = np.linalg.norm(nose - mid_shoulder)\n",
    "\n",
    "    nose_angle = calculate_angle_nose_shoulder_yaxis(nose, left_shoulder, right_shoulder)\n",
    "\n",
    "#         # Calculate shoulder width to use as a normalizing factor\n",
    "#         shoulder_width = np.linalg.norm(left_shoulder - right_shoulder)\n",
    "\n",
    "#         # Normalized nose distance\n",
    "#         normalized_nose_distance = nose_distance / shoulder_width if shoulder_width != 0 else 0\n",
    "\n",
    "    # Combine into a bigger feature vector\n",
    "    features = np.array([\n",
    "        shoulder_length,\n",
    "        horizontal_angle,\n",
    "        vertical_angle,\n",
    "        depth_angle,\n",
    "        nose_deviation,\n",
    "        z_offset,             # existing feature for forward/back separation\n",
    "        nose_distance,  # new feature for backward/normal separation\n",
    "        nose_angle\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def calculate_angle_nose_shoulder_yaxis(nose_vector, left_shoulder, right_shoulder):\n",
    "    \"\"\"\n",
    "    Calculate the angle between the nose position and the shoulder midpoint relative to the y-axis.\n",
    "\n",
    "    Parameters:\n",
    "        nose_vector (numpy array): A vector [x, y, z] representing the nose position.\n",
    "        left_shoulder (numpy array): A vector [x, y, z] representing the left shoulder position.\n",
    "        right_shoulder (numpy array): A vector [x, y, z] representing the right shoulder position.\n",
    "\n",
    "    Returns:\n",
    "        float: The angle in radians between the nose and the shoulder midpoint relative to the y-axis.\n",
    "    \"\"\"\n",
    "    # Calculate the midpoint of the shoulders\n",
    "    shoulder_midpoint = (left_shoulder + right_shoulder) / 2.0\n",
    "\n",
    "    # Calculate the vector difference between the nose and shoulder midpoint\n",
    "    vector_diff = nose_vector - shoulder_midpoint\n",
    "\n",
    "    # Define the y-axis vector\n",
    "    y_axis_vector = np.array([0, 1, 0])\n",
    "\n",
    "    # Calculate the magnitudes of the vectors\n",
    "    mag_vector_diff = np.linalg.norm(vector_diff)\n",
    "    mag_y_axis = np.linalg.norm(y_axis_vector)\n",
    "\n",
    "    # Prevent division by zero\n",
    "    if mag_vector_diff == 0:\n",
    "        raise ValueError(\"Vector difference is zero, cannot compute angle.\")\n",
    "\n",
    "    # Calculate the dot product\n",
    "    dot_product = np.dot(vector_diff, y_axis_vector)\n",
    "\n",
    "    # Calculate the angle (in radians)\n",
    "    angle = np.arccos(dot_product / (mag_vector_diff * mag_y_axis))\n",
    "\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave one out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb5752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:44:13.933962Z",
     "start_time": "2024-12-16T20:44:13.914595Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Filepaths for keypoints\n",
    "keypoints_files = {\n",
    "    \"Normal\": \"/Users/idrissunmola/Documents/Idris_macbook/Fall_24/ml_proj/SitSmartBackend/keypoints/normal_keypoints/keypoints_img_coord.npy\",\n",
    "    \"Forward\": \"/Users/idrissunmola/Documents/Idris_macbook/Fall_24/ml_proj/SitSmartBackend/keypoints/forward_keypoints/keypoints_img_coord.npy\",\n",
    "    \"Backward\": \"/Users/idrissunmola/Documents/Idris_macbook/Fall_24/ml_proj/SitSmartBackend/keypoints/backward_keypoints/keypoints_img_coord.npy\"\n",
    "}\n",
    "\n",
    "# Frame ranges for the excluded subject\n",
    "exclude_ranges = {\n",
    "    \"Normal\": (1357, 3595),  # Exclude frames 1357 to 3595\n",
    "    \"Forward\": (0, 1268),    # Exclude frames 0 to 1268\n",
    "    \"Backward\": (0, 1264)    # Exclude frames 0 to 1264\n",
    "}\n",
    "\n",
    "# Function to exclude frames\n",
    "def exclude_keypoints(file, exclude_range):\n",
    "    keypoints = np.load(file)\n",
    "    total_frames = keypoints.shape[0]\n",
    "    keep_indices = list(range(0, exclude_range[0])) + list(range(exclude_range[1] + 1, total_frames))\n",
    "    excluded = keypoints[exclude_range[0]:exclude_range[1] + 1]\n",
    "    remaining = keypoints[keep_indices]\n",
    "    return remaining, excluded\n",
    "\n",
    "train_keypoints = {}\n",
    "test_keypoints = {}\n",
    "\n",
    "for posture, file in keypoints_files.items():\n",
    "    train_keypoints[posture], test_keypoints[posture] = exclude_keypoints(file, exclude_ranges[posture])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ba059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:44:14.562049Z",
     "start_time": "2024-12-16T20:44:13.942960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract features from keypoints\n",
    "def extract_features_batch(keypoints):\n",
    "    return np.array([extract_features(kp) for kp in keypoints])\n",
    "\n",
    "# Prepare training and test datasets\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "posture_labels = {\"Normal\": 0, \"Forward\": 2, \"Backward\": 1}\n",
    "\n",
    "for posture, label in posture_labels.items():\n",
    "    # Training data\n",
    "    features_train = extract_features_batch(train_keypoints[posture])\n",
    "    X_train.append(features_train)\n",
    "    y_train.append(np.full(features_train.shape[0], label))\n",
    "    \n",
    "    # Test data\n",
    "    features_test = extract_features_batch(test_keypoints[posture])\n",
    "    X_test.append(features_test)\n",
    "    y_test.append(np.full(features_test.shape[0], label))\n",
    "\n",
    "# Combine all postures\n",
    "X_train = np.vstack(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "X_test = np.vstack(X_test)\n",
    "y_test = np.concatenate(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee4f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:44:17.360678Z",
     "start_time": "2024-12-16T20:44:14.574011Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4eb14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:46:42.515197Z",
     "start_time": "2024-12-16T20:46:11.509557Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine features and labels into a DataFrame\n",
    "feature_names = [\n",
    "    \"Shoulder Length\",\n",
    "    \"Horizontal Angle\",\n",
    "    \"Vertical Angle\",\n",
    "    \"Depth Angle\",\n",
    "    \"Nose Deviation\",\n",
    "    \"Z Offset\",\n",
    "    \"Nose Distance\",\n",
    "    \"Nose Angle\"\n",
    "]\n",
    "train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "train_df['Label'] = y_train\n",
    "\n",
    "# Pairplot of feature distributions by class\n",
    "sns.pairplot(\n",
    "    train_df,\n",
    "    hue='Label',\n",
    "    palette={0: 'blue', 1: 'orange', 2: 'green'},\n",
    "    diag_kind='kde',\n",
    "    markers=['o', 's', 'D']\n",
    ")\n",
    "plt.suptitle('Feature Distributions by Posture Class', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2abe6d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:47:02.399662Z",
     "start_time": "2024-12-16T20:47:02.193822Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=['Normal', 'Backward', 'Forward'], cmap='Blues'\n",
    ")\n",
    "cm_display.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e72068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:47:29.280269Z",
     "start_time": "2024-12-16T20:47:21.316964Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Binarize labels for multi-class ROC\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "# Train One-vs-Rest classifier\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
    "clf.fit(X_train_scaled, label_binarize(y_train, classes=[0, 1, 2]))\n",
    "y_score = clf.predict_proba(X_test_scaled)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['blue', 'orange', 'green']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f\"Class {i} (area = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Each Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989c661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:47:35.430905Z",
     "start_time": "2024-12-16T20:47:35.279056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importances from the Random Forest classifier\n",
    "importances = clf.estimators_[0].feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(importances)), importances[sorted_indices], align='center')\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in sorted_indices], rotation=45)\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93861cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:47:58.137075Z",
     "start_time": "2024-12-16T20:47:57.968871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify misclassified frames\n",
    "misclassified_indices = np.where(y_pred != y_test)[0]\n",
    "\n",
    "# Print misclassified frame indices\n",
    "print(\"Misclassified Frame Indices:\", misclassified_indices)\n",
    "\n",
    "# Histogram of misclassified frames by class\n",
    "misclassified_labels = y_test[misclassified_indices]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(misclassified_labels, bins=3, kde=False, color='red')\n",
    "plt.title('Misclassified Frames by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1, 2], labels=['Normal', 'Backward', 'Forward'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7545e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:50:56.615327Z",
     "start_time": "2024-12-16T20:50:42.389138Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply RFE for dimensionality reduction\n",
    "rfe = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=4)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = [feature_names[i] for i in range(len(feature_names)) if rfe.support_[i]]\n",
    "print(\"Selected Features via RFE:\", selected_features)\n",
    "\n",
    "# Transform the data to reduced dimensions\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2a07e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:51:13.945514Z",
     "start_time": "2024-12-16T20:51:06.663510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine features and labels into a DataFrame\n",
    "rfe_df = pd.DataFrame(X_train_rfe, columns=selected_features)\n",
    "rfe_df['Label'] = y_train  # Add labels for coloring\n",
    "\n",
    "# Generate a pairplot for the reduced features\n",
    "sns.pairplot(\n",
    "    rfe_df,\n",
    "    hue='Label',\n",
    "    palette={0: 'blue', 1: 'orange', 2: 'green'},\n",
    "    diag_kind='kde',\n",
    "    markers=['o', 's', 'D']\n",
    ")\n",
    "plt.suptitle('Pairplot of RFE-Reduced Features', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8c38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:53:22.688110Z",
     "start_time": "2024-12-16T20:53:22.680551Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values in training and testing data\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace 'mean' with 'median' if needed\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c85af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:53:38.928502Z",
     "start_time": "2024-12-16T20:53:38.922603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows with NaN values\n",
    "mask_train = ~np.isnan(X_train).any(axis=1)\n",
    "X_train = X_train[mask_train]\n",
    "y_train = y_train[mask_train]\n",
    "\n",
    "mask_test = ~np.isnan(X_test).any(axis=1)\n",
    "X_test = X_test[mask_test]\n",
    "y_test = y_test[mask_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb9e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:54:47.516477Z",
     "start_time": "2024-12-16T20:54:39.960657Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA after preprocessing\n",
    "pca = PCA(n_components=4)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Print explained variance ratios\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance by PCA Components:\", explained_variance)\n",
    "\n",
    "# Create a DataFrame for PCA components\n",
    "pca_columns = [f\"PC{i+1}\" for i in range(X_train_pca.shape[1])]\n",
    "pca_df = pd.DataFrame(X_train_pca, columns=pca_columns)\n",
    "pca_df['Label'] = y_train\n",
    "\n",
    "# Pairplot for PCA components\n",
    "sns.pairplot(\n",
    "    pca_df,\n",
    "    hue='Label',\n",
    "    palette={0: 'blue', 1: 'orange', 2: 'green'},\n",
    "    diag_kind='kde',\n",
    "    markers=['o', 's', 'D']\n",
    ")\n",
    "plt.suptitle('Pairplot of PCA-Reduced Features', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd2b90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T20:55:12.043700Z",
     "start_time": "2024-12-16T20:55:06.503715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and evaluate using RFE-reduced features\n",
    "clf_rfe = RandomForestClassifier(random_state=42)\n",
    "clf_rfe.fit(X_train_rfe, y_train)\n",
    "y_pred_rfe = clf_rfe.predict(X_test_rfe)\n",
    "print(\"Classification Report (RFE-Reduced):\")\n",
    "print(classification_report(y_test, y_pred_rfe))\n",
    "\n",
    "# Train and evaluate using PCA-reduced features\n",
    "clf_pca = RandomForestClassifier(random_state=42)\n",
    "clf_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = clf_pca.predict(X_test_pca)\n",
    "print(\"Classification Report (PCA-Reduced):\")\n",
    "print(classification_report(y_test, y_pred_pca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79446a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:01:31.103919Z",
     "start_time": "2024-12-16T21:01:31.099829Z"
    }
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0eff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:00:20.304816Z",
     "start_time": "2024-12-16T21:00:20.290547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save RFE-reduced features and labels\n",
    "np.save('reduced_features_rfe.npy', X_train_rfe)  # Training features (RFE)\n",
    "np.save('reduced_features_rfe_test.npy', X_test_rfe)  # Testing features (RFE)\n",
    "np.save('labels_rfe_train.npy', y_train)  # Training labels (RFE)\n",
    "np.save('labels_rfe_test.npy', y_test)  # Testing labels (RFE)\n",
    "\n",
    "# Save PCA-reduced features and labels\n",
    "np.save('reduced_features_pca.npy', X_train_pca)  # Training features (PCA)\n",
    "np.save('reduced_features_pca_test.npy', X_test_pca)  # Testing features (PCA)\n",
    "np.save('labels_pca_train.npy', y_train)  # Training labels (PCA)\n",
    "np.save('labels_pca_test.npy', y_test)  # Testing labels (PCA)\n",
    "\n",
    "print(\"Reduced datasets and labels saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ebc930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:16:58.776061Z",
     "start_time": "2024-12-16T21:16:47.301908Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def stratified_k_fold_evaluation(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_reports = []\n",
    "    fold_conf_matrices = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        # Split the data\n",
    "        X_train_cv, X_test_cv = X[train_idx], X[test_idx]\n",
    "        y_train_cv, y_test_cv = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Train the classifier\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "        clf.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred_cv = clf.predict(X_test_cv)\n",
    "        report = classification_report(y_test_cv, y_pred_cv, output_dict=True)\n",
    "        cm = confusion_matrix(y_test_cv, y_pred_cv)\n",
    "\n",
    "        fold_reports.append(report)\n",
    "        fold_conf_matrices.append(cm)\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Normal\", \"Backward\", \"Forward\"],\n",
    "                    yticklabels=[\"Normal\", \"Backward\", \"Forward\"])\n",
    "        plt.title(f\"Confusion Matrix - Fold {fold + 1}\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "    return fold_reports, fold_conf_matrices\n",
    "\n",
    "\n",
    "rfe_reports, rfe_matrices = stratified_k_fold_evaluation(X_train_rfe, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36618d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:18:32.691600Z",
     "start_time": "2024-12-16T21:18:29.708279Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "def plot_roc_and_pr_curves(X_train, X_test, y_train, y_test, n_classes=3):\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test == i, y_prob[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"Class {i} (AUC = {auc(fpr, tpr):.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(n_classes):\n",
    "        precision, recall, _ = precision_recall_curve(y_test == i, y_prob[:, i])\n",
    "        plt.plot(recall, precision, label=f\"Class {i}\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_and_pr_curves(X_train_rfe, X_test_rfe, y_train, y_test, n_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892427c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:24:20.263007Z",
     "start_time": "2024-12-16T21:24:10.191918Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importance_stability_safe(X, y, n_splits=5):\n",
    "    # Ensure dimensions match\n",
    "    assert X.shape[0] == y.shape[0], \"Mismatch between X and y dimensions.\"\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    feature_importances = np.zeros((n_splits, X.shape[1]))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        feature_importances[fold] = clf.feature_importances_\n",
    "\n",
    "    # Plot feature importance stability\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(feature_importances, labels=selected_features, vert=False)\n",
    "    plt.title(\"Feature Importance Stability Across Folds\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "\n",
    "feature_importance_stability_safe(X_train_rfe, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d5231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:31:24.814686Z",
     "start_time": "2024-12-16T21:28:14.740699Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def bootstrap_evaluation(X, y, n_iterations=100, test_size=0.2):\n",
    "    reports = []\n",
    "    for i in range(n_iterations):\n",
    "        # Bootstrap sampling\n",
    "        X_train, y_train = resample(X, y, replace=True, n_samples=int((1 - test_size) * len(y)), random_state=i)\n",
    "        X_test, y_test = resample(X, y, replace=False, n_samples=int(test_size * len(y)), random_state=i)\n",
    "\n",
    "        # Train the classifier\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = clf.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        reports.append(report)\n",
    "\n",
    "        if i < 5:  # Plot confusion matrices for the first few iterations\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                        xticklabels=[\"Normal\", \"Backward\", \"Forward\"],\n",
    "                        yticklabels=[\"Normal\", \"Backward\", \"Forward\"])\n",
    "            plt.title(f\"Confusion Matrix - Bootstrap Iteration {i + 1}\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.show()\n",
    "\n",
    "    return reports\n",
    "\n",
    "bootstrap_reports = bootstrap_evaluation(X_train_rfe, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffba6b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:47:58.367294Z",
     "start_time": "2024-12-16T21:47:57.641854Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def class_specific_leave_one_out(X, y, test_fraction=0.1):\n",
    "    class_reports = []\n",
    "    known_labels = np.unique(y)  # Get all possible labels\n",
    "\n",
    "    for class_label in known_labels:\n",
    "        # Split the data for this class\n",
    "        X_class = X[y == class_label]\n",
    "        y_class = y[y == class_label]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_class, y_class, test_size=test_fraction, random_state=42)\n",
    "\n",
    "        # Train on the rest of the data\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on the test set for this class\n",
    "        y_pred = clf.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "        # Confusion matrix with known labels\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=known_labels)\n",
    "\n",
    "        class_reports.append(report)\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Normal\", \"Backward\", \"Forward\"],\n",
    "                    yticklabels=[\"Normal\", \"Backward\", \"Forward\"])\n",
    "        plt.title(f\"Class {class_label} - Leave-One-Out Evaluation\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "    return class_reports\n",
    "\n",
    "class_specific_reports = class_specific_leave_one_out(X_train_rfe, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e441e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:31:28.320579Z",
     "start_time": "2024-12-16T21:31:25.595840Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def test_time_augmentation_evaluation(X_test, y_test, augmentations):\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "    augmented_predictions = []\n",
    "    for aug in augmentations:\n",
    "        # Apply augmentation\n",
    "        X_augmented = aug(X_test)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = clf.predict(X_augmented)\n",
    "        augmented_predictions.append(y_pred)\n",
    "\n",
    "    # Aggregate predictions (majority vote)\n",
    "    y_pred_final = np.array(augmented_predictions).mean(axis=0).round().astype(int)\n",
    "\n",
    "    # Evaluation\n",
    "    report = classification_report(y_test, y_pred_final, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Normal\", \"Backward\", \"Forward\"],\n",
    "                yticklabels=[\"Normal\", \"Backward\", \"Forward\"])\n",
    "    plt.title(\"Confusion Matrix - Test-Time Augmentation\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    return report\n",
    "\n",
    "augmentations = [lambda x: x, lambda x: x + np.random.normal(0, 0.01, x.shape)]\n",
    "tta_report = test_time_augmentation_evaluation(X_test_rfe, y_test, augmentations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
